{
 "metadata": {
  "name": "",
  "signature": "sha256:a203962ebc770ac6dcfcb4a42f1903aee612748fba9072fb3e2cfe78de750ef2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": [],
     "source": [
      "> This is one of the 100 recipes of the [IPython Cookbook](http://ipython-books.github.io/), the definitive guide to high-performance scientific computing and data science in Python.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 8.5. Using Support Vector Machines for classification tasks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Let's do the traditional imports."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn\n",
      "import sklearn.datasets as ds\n",
      "import sklearn.cross_validation as cv\n",
      "import sklearn.grid_search as gs\n",
      "import sklearn.svm as svm\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2. We generate 2D points and assign a binary label according to a linear operation on the coordinates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.random.randn(200, 2)\n",
      "y = X[:, 0] + X[:, 1] > 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3. We now fit a linear **Support Vector Classifier** (SVC). This classifier tries to separate the two groups of points with a linear boundary (a line here, more generally a hyperplane)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We train the classifier.\n",
      "est = svm.LinearSVC()\n",
      "est.fit(X, y);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4. We define a function that displays the boundaries and decision function of a trained classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We generate a grid in the square [-3,3 ]^2.\n",
      "xx, yy = np.meshgrid(np.linspace(-3, 3, 500),\n",
      "                     np.linspace(-3, 3, 500))\n",
      "# This function takes a SVM estimator as input.\n",
      "def plot_decision_function(est):\n",
      "    # We evaluate the decision function on the grid.\n",
      "    Z = est.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
      "    Z = Z.reshape(xx.shape)\n",
      "    cmap = plt.cm.Blues\n",
      "    # We display the decision function on the grid.\n",
      "    plt.figure(figsize=(5,5));\n",
      "    plt.imshow(Z,\n",
      "                extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
      "                aspect='auto', origin='lower', cmap=cmap);\n",
      "    # We display the boundaries.\n",
      "    plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
      "                colors='k');\n",
      "    # We display the points with their true labels.\n",
      "    plt.scatter(X[:, 0], X[:, 1], s=30, c=.5+.5*y, lw=1, \n",
      "                cmap=cmap, vmin=0, vmax=1);\n",
      "    plt.axhline(0, color='k', ls='--');\n",
      "    plt.axvline(0, color='k', ls='--');\n",
      "    plt.xticks(());\n",
      "    plt.yticks(());\n",
      "    plt.axis([-3, 3, -3, 3]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5. Let's take a look at the classification results with the linear SVC."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_decision_function(est);\n",
      "plt.title(\"Linearly separable, linear SVC\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The linear SVC tried to separate the points with a line and it did a pretty good job."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6. We now modify the labels with a *XOR* function. A point's label is 1 if the coordinates have different signs. This classification is not linearly separable. Therefore, a linear SVC fails completely."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
      "# We train the classifier.\n",
      "est = gs.GridSearchCV(svm.LinearSVC(), \n",
      "                      {'C': np.logspace(-3., 3., 10)});\n",
      "est.fit(X, y);\n",
      "print(\"Score: {0:.1f}\".format(\n",
      "      cv.cross_val_score(est, X, y).mean()))\n",
      "# Plot the decision function.\n",
      "plot_decision_function(est);\n",
      "plt.title(\"XOR, linear SVC\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "7. Fortunately, it is possible to use non-linear SVCs by using non-linear **kernels**. Kernels specify a non-linear transformation of the points into a higher-dimensional space. Transformed points in this space are assumed to be more linearly separable, although they are not necessarily in the original space. By default, the `SVC` classifier in scikit-learn uses the **Radial Basis Function** (RBF) kernel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
      "est = gs.GridSearchCV(svm.SVC(), \n",
      "                      {'C': np.logspace(-3., 3., 10),\n",
      "                    'gamma': np.logspace(-3., 3., 10)});\n",
      "est.fit(X, y);\n",
      "print(\"Score: {0:.3f}\".format(\n",
      "      cv.cross_val_score(est, X, y).mean()))\n",
      "plot_decision_function(est.best_estimator_);\n",
      "plt.title(\"XOR, non-linear SVC\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This time, the non-linear SVC does a pretty good job at classifying these non-linearly separable points."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> You'll find all the explanations, figures, references, and much more in the book (to be released later this summer).\n",
      "\n",
      "> [IPython Cookbook](http://ipython-books.github.io/), by [Cyrille Rossant](http://cyrille.rossant.net), Packt Publishing, 2014 (400 pages). [Get a 50% discount by pre-ordering now](http://www.packtpub.com/ipython-interactive-computing-and-visualization-cookbook/book) with the code `PICVCEB` (time-limited offer)!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}